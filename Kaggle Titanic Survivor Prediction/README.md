## Kaggle Competition: Titanic - Machine Learning from Disaster ##

### Description: ###
*"On April 15, 1912, during her maiden voyage, the widely considered “unsinkable” RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren’t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew." (Kaggle Competition Homepage)*

This competition provides two datasets of passenger data. One dataset (train) includes passenger data to include whether or not the passenger survived, this dataset was used to build the predicitive model(s). The second dataset (test) included passengers aboard the Titanic not included in the first dataset and did not include if they survived or not. The predictive model was ran on the second dataset. The results of the predicitons were submitted to the [Kaggle competition website](https://www.kaggle.com/c/titanic). 

### Model Results and Leaderboard Ranking ###
- On training data: **81 - 83%**
- Competition Submission:  **78.7%**   
- Competition Ranking: 1,839th out of 14,017 participants

### Methods ###
- Data Visualization
- Data Cleaning
- Feature Engineering
- Machine Learning

### Tools ###
- Python
- Pandas
- Numpy
- Matplotlib
- Seaborn
- Sklearn
- Juypiter Notebooks

### Status ###
*Completed*
